{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNF1_WoVyJwK",
        "outputId": "9a80d279-3191-42a9-a56c-f1f0dab14af3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-et6ma3lc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-et6ma3lc\n",
            "  Resolved https://github.com/huggingface/transformers to commit 6b550462139655d488d4c663086a63e98713c6b9\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.49.0.dev0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.49.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (2025.1.31)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.49.0.dev0-py3-none-any.whl size=10719728 sha256=2e5ec4301513a33578956541343ca12c7ec83e20753c83c6bd5872f66e876fac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jw0uy_nx/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.2\n",
            "    Uninstalling transformers-4.48.2:\n",
            "      Successfully uninstalled transformers-4.48.2\n",
            "Successfully installed transformers-4.49.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--7S9gnuyVWr",
        "outputId": "1d340c56-9844-438b-a3ce-cf6fbcb8c37f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf3CfTWKxvJL",
        "outputId": "e9aace5f-17c5-43f7-9e53-16bb93ca019a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "from transformers import set_seed\n",
        "set_seed(42)\n",
        "\n",
        "os.environ['HF_TOKEN']=\"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\"\n",
        "login(token = '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')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import httpx\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Your Hugging Face API key\n",
        "api_key = \"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\"\n",
        "\n",
        "# List of five documents\n",
        "documents = [\n",
        "    \"\"\"The LLaMA models, developed by Meta AI, are open-weight large language models optimized for efficiency.\n",
        "    They offer state-of-the-art performance on various NLP tasks while being significantly smaller in size\n",
        "    compared to other models. LLaMA 3.1 is the latest iteration, improving instruction-following and factual consistency.\"\"\",\n",
        "\n",
        "    \"\"\"Transformers have revolutionized Natural Language Processing by introducing attention mechanisms,\n",
        "    enabling models to process entire input sequences simultaneously. BERT, GPT, and T5 are examples of\n",
        "    architectures leveraging transformers, each designed for different NLP applications such as text generation,\n",
        "    translation, and classification.\"\"\",\n",
        "\n",
        "    \"\"\"Reinforcement Learning with Human Feedback (RLHF) enhances AI models by integrating human preferences\n",
        "    into training. It has been widely used in chatbots like ChatGPT to align responses with human values,\n",
        "    making models safer and more useful in real-world applications.\"\"\",\n",
        "\n",
        "    \"\"\"The field of adversarial attacks in AI focuses on identifying vulnerabilities in deep learning models.\n",
        "    Attackers use subtle perturbations to mislead models into making incorrect predictions. Robustness techniques\n",
        "    like adversarial training help mitigate these threats, improving AI security.\"\"\",\n",
        "\n",
        "    \"\"\"Explainability in AI ensures that models provide transparent and interpretable results. Methods like SHAP\n",
        "    and LIME help users understand model decisions, promoting trust in AI systems across critical domains\n",
        "    like healthcare and finance.\"\"\"\n",
        "]\n",
        "\n",
        "# Define user query\n",
        "query = \"How do adversarial attacks impact AI models, and what techniques help mitigate them?\"\n",
        "\n",
        "# Prepare context from documents\n",
        "context = \"\\n\\n\".join([f\"Document {i+1}: {doc}\" for i, doc in enumerate(documents)])\n",
        "\n",
        "# Construct prompt for LLaMA\n",
        "prompt = f\"Using the information from the following documents, answer the question concisely:\\n\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "\n",
        "# instead of `from openai import OpenAI`\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "# Define model endpoint\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "API_URL = f\"https://api-inference.huggingface.co/models/{MODEL_NAME}\"\n",
        "\n",
        "# instead of `client = OpenAI(...)`\n",
        "client = InferenceClient(\n",
        "    base_url=API_URL,\n",
        "    api_key=api_key,\n",
        ")\n",
        "\n",
        "output = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ],\n",
        "    stream=True,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "\n",
        "\n",
        "# create variables to collect the stream of chunks\n",
        "collected_chunks = []\n",
        "collected_messages = []\n",
        "# iterate through the stream of events\n",
        "for chunk in output:\n",
        "    collected_chunks.append(chunk)  # save the event response\n",
        "    chunk_message = chunk.choices[0].delta.content  # extract the message\n",
        "    collected_messages.append(chunk_message)  # save the message\n",
        "\n",
        "# clean None in collected_messages\n",
        "collected_messages = [m for m in collected_messages if m is not None]\n",
        "full_reply_content = ''.join(collected_messages)\n",
        "print(f\"Full conversation received: {full_reply_content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwXUeGFz6WzZ",
        "outputId": "512105f1-669c-4077-e39c-f7b133c1d409"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full conversation received: Adversarial attacks in AI exploit vulnerabilities by introducing subtle perturbations to input data, which can cause models to make incorrect predictions. This undermines the trustworthiness and reliability of AI systems.\n",
            "\n",
            "To mitigate adversarial attacks, techniques like adversarial training are used. Adversarial training involves training models on adversarially crafted inputs to make them more robust against such perturbations. This approach strengthens the models' defenses against potential vulnerabilities.\n"
          ]
        }
      ]
    }
  ]
}